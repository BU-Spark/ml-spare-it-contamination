{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNxoO6PX4Z8F"
   },
   "source": [
    "# Spare-it Proof of Concept (PoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEGeY9OH4W_V"
   },
   "source": [
    "### Objective: \n",
    "estimate automatically composition of waste inside bins based on itms visible on images\n",
    "\n",
    "### High-Level Goal: \n",
    "count multiple labels of waste (classification); use open source\n",
    "\n",
    "### Steps: \n",
    "1. count instances of each mterial type in each image\n",
    "2. apply sorting rules to material types based on type of bin (compost/mixed recycling/trash)\n",
    "\n",
    "### Result: \n",
    "1. compute composition of waste (% of items of each material type)\n",
    "2. the waste contamination rate, which is the proportion of items thave have been mistakingly put in a compost or recycling bin,  over the total number of visible objects.\n",
    "3. the missed opportunities rate, which is the proportion of items that could have been recycled or composted in a trash bin,  over the total number of visible objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install torch ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.0.196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download COCO val\n",
    "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
    "!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!yolo train data=dataset.yaml model=yolov8s.yaml epochs=50 batch=16 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "folder_path = '/Users/tessa/Desktop/spare-it-images' \n",
    "\n",
    "# Supported image extensions\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "# List to store loaded images\n",
    "images = []\n",
    "\n",
    "# get all list of files in the path\n",
    "files = os.listdir(folder_path)\n",
    "print(f\"Total number of files in the directory: {len(files)}\")\n",
    "\n",
    "# print number of json files\n",
    "json_files = [file for file in files if file.endswith('.json')]\n",
    "print(f\"Number of .json files in the folder: {len(json_files)}\")\n",
    "\n",
    "# print number of image files\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.gif']\n",
    "image_files = [file for file in files if any(file.endswith(ext) for ext in image_extensions)]\n",
    "print(f\"Number of image files in the folder: {len(image_files)}\")\n",
    "\n",
    "# list out all other files extension\n",
    "other_files = [file for file in files if file not in json_files + image_files]\n",
    "print(f\"Files not classified as JSON or image files: {other_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "# Find all images with a corresponding JSON file\n",
    "available_images = []\n",
    "for file in os.listdir(folder_path):\n",
    "    name, ext = os.path.splitext(file)\n",
    "    if ext.lower() in image_extensions and os.path.exists(os.path.join(folder_path, name + '.json')):\n",
    "        available_images.append(file)\n",
    "\n",
    "print(f\"Found {len(available_images)} images with corresponding JSON files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    annotations = data['annotations']\n",
    "    # Process annotations as needed, e.g., extracting bounding boxes or categories\n",
    "    # This is an example and may need to be adapted\n",
    "    for ann in annotations:\n",
    "        bbox = ann['bbox']  # Example: [x, y, width, height]\n",
    "        category_id = ann['category_id']\n",
    "        # Lookup category name (example)\n",
    "        category_name = next((cat['name'] for cat in data['categories'] if cat['id'] == category_id), None)\n",
    "        print(f\"Annotation: {category_name}, BBox: {bbox}\")\n",
    "\n",
    "# Example usage for the first image with a corresponding JSON file\n",
    "if available_images:\n",
    "    first_image_json_path = os.path.join(folder_path, os.path.splitext(available_images[0])[0] + '.json')\n",
    "    load_annotations(first_image_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing your images\n",
    "image_dir = '/Users/tessa/Desktop/spare-it-images'  # Update this path\n",
    "\n",
    "# Supported image formats\n",
    "image_formats = ('.bmp', '.dng', '.jpeg', '.jpg', '.mpo', '.png', '.tif', '.tiff', '.webp')\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for file_name in os.listdir(image_dir):\n",
    "    # Check if the file is an image based on its extension\n",
    "    if file_name.lower().endswith(image_formats):\n",
    "        image_path = os.path.join(image_dir, file_name)  # Construct the full path to the image\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(image_path)\n",
    "\n",
    "        # Inspect the type and structure of results\n",
    "        print(f\"Processing {file_name}:\")\n",
    "        print(type(results))\n",
    "        print(len(results))\n",
    "        if len(results) > 0:\n",
    "            print(type(results[0]))\n",
    "            print(results[0])\n",
    "    else:\n",
    "        print(f\"Skipping {file_name}: Not an image file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "results = model(image_path)\n",
    "\n",
    "# Inspect the type and structure of results\n",
    "print(type(results))\n",
    "print(len(results))\n",
    "if len(results) > 0:\n",
    "    print(type(results[0]))\n",
    "    print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming detections is obtained correctly from 'results'\n",
    "if hasattr(results, 'boxes') and results.boxes:\n",
    "    detections = results.boxes.xyxy[0]  # Access detections assuming they're stored in this attribute\n",
    "\n",
    "    # Debugging: Print the structure of the first detection\n",
    "    if len(detections) > 0:\n",
    "        print(\"Detection structure:\", detections[0].shape)\n",
    "        print(\"Detection content:\", detections[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Directory containing images\n",
    "directory_path = '/Users/tessa/Desktop/spare-it-images'\n",
    "\n",
    "# Supported image formats\n",
    "image_formats = ('.bmp', '.dng', '.jpeg', '.jpg', '.mpo', '.png', '.tif', '.tiff', '.webp')\n",
    "\n",
    "# Loop through files in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # Construct the full file path\n",
    "    image_path = os.path.join(directory_path, file_name)\n",
    "    \n",
    "    # Check if the path is an actual file and has a supported image format\n",
    "    if os.path.isfile(image_path) and file_name.lower().endswith(image_formats):\n",
    "        # Open and visualize the image\n",
    "        img = Image.open(image_path)\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(img)\n",
    "        plt.axis('off')  # Hides the axis\n",
    "        plt.title(file_name)  # Optional: add the file name as title\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'results' is the list containing your model's inference output\n",
    "results_obj = results[0]  # Extracting the Results object assuming it's the first element\n",
    "\n",
    "# Print the type and available attributes or methods of the results object\n",
    "print(f\"Type of results_obj: {type(results_obj)}\")\n",
    "print(dir(results_obj))  # This will list all attributes and methods\n",
    "\n",
    "# If 'boxes' is an attribute, investigate its structure further\n",
    "if hasattr(results_obj, 'boxes'):\n",
    "    print(\"Found 'boxes' attribute.\")\n",
    "    print(\"Type of 'boxes':\", type(results_obj.boxes))\n",
    "    print(\"Content of 'boxes':\", results_obj.boxes)\n",
    "\n",
    "    # If 'boxes' contains tensor data, let's try to print its size\n",
    "    if hasattr(results_obj.boxes, 'xyxy'):\n",
    "        print(\"Found 'xyxy' attribute in 'boxes'.\")\n",
    "        print(\"Type of 'boxes.xyxy':\", type(results_obj.boxes.xyxy))\n",
    "        print(\"Number of detections:\", len(results_obj.boxes.xyxy[0]))\n",
    "        for det in results_obj.boxes.xyxy[0]:\n",
    "            print(det)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above provides insight into the strcture of the results_obj and specifically the boxes attribute containing detection data. The boxes object within result_obj has an xyxy attribute which is a tensor containing the bounding box coordinates in the format[x1, y1, x2, y2], alongside other attributes such as cls for class IDs and conf for confidence scores.\n",
    "\n",
    "From this, we can construct a visualization script that directly utilizes this structured data. Notably, the xyxy tensor's structure indicates each component (x1, y1, x2, y2) is individually listed when iterated, rather than as a collective set per detection, which is unusual. Normally, you would expect a single iteration to yield all components of a detection (i.e., a bounding box and possibly class and confidence) together. However, the provided output suggests we might need to access the complete tensor directly rather than iterating over its elements for individual bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Load the original image from the path\n",
    "img = Image.open(results_obj.path)\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(img)\n",
    "\n",
    "# Assuming 'xyxy' is the attribute containing bounding box coordinates\n",
    "bbox_tensor = results_obj.boxes.xyxy[0]  # Access the tensor directly\n",
    "\n",
    "# The provided output suggests accessing the whole detection tensor at once\n",
    "# Here we assume the tensor structure is [x1, y1, x2, y2, conf, cls_id] for each detection\n",
    "if bbox_tensor.shape[0] > 0:  # Ensure there are detections\n",
    "    # As per the output, let's directly use the tensor for plotting\n",
    "    x1, y1, x2, y2 = bbox_tensor[0], bbox_tensor[1], bbox_tensor[2], bbox_tensor[3]\n",
    "    conf = results_obj.boxes.conf  # Assuming this is how confidence is accessed\n",
    "    cls_id = results_obj.boxes.cls  # Assuming this is how class ID is accessed\n",
    "    \n",
    "    # Draw the bounding box\n",
    "    rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Label with class name and confidence\n",
    "    label = f\"{results_obj.names[int(cls_id[0].item())]}: {conf[0].item():.2f}\"\n",
    "    ax.text(x1, y1, label, color='white', va='top', fontsize=8, bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "plt.axis('off')  # Hide axes ticks\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Adjustments:\n",
    "This script assumes the results_obj.boxes.xyxy tensor directly provides the bounding box coordinates for the first detection. Given your output, it seems we might need to reconsider how the detections are iterated or accessed, as the structure provided does not clearly delineate multiple detections.\n",
    "\n",
    "Access to conf and cls directly from results_obj.boxes is based on your structure insight, but might need adjustment if these attributes store multiple values or are structured differently.\n",
    "This visualization script is tailored to the specific structure you've encountered and the output shared. It's important to adjust the script if the assumptions made here about accessing the conf and cls_id do not hold or if further clarification on the structure is provided. The unusual formatting of the detection output may require further adjustment or clarification from Ultralytics YOLO documentation or support resources to ensure accurate access and representation of the detection data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
