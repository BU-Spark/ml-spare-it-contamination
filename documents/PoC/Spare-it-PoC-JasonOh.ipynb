{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d5eec6-e0a2-4d8e-acf8-19147455bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before delving into the implementation of YOLOv8 for our Proof of Concept (PoC), \n",
    "# it's crucial to consider a few key aspects regarding the dataset provided by Spare-it. \n",
    "# There are notable characteristics we must address to ensure the success of our model.\n",
    "\n",
    "# Firstly, our dataset exhibits class imbalance, where certain recyclable \n",
    "# classes are underrepresented or absent entirely. For instance, labels \n",
    "# like \"paper towel\" may occur frequently, while others may be scarce. \n",
    "# To mitigate this imbalance, we plan to leverage pretrained models. \n",
    "# These models not only help address class imbalances but also enhance the \n",
    "# overall accuracy of our model as Spare-it's dataset expands and evolves.\n",
    "\n",
    "# Furthermore, within our dataset, we encounter a distinction between material \n",
    "# classes and specific names (e.g., \"paper towel\"). Notably, the material class \n",
    "# serves as a superclass encompassing various specific names. Therefore, achieving \n",
    "# optimal performance on these specific names is crucial for enhancing the overall model accuracy.\n",
    "\n",
    "# Our initial step involves transforming Spare-it's dataset, currently in cocojson \n",
    "# format, to align with the requirements of YOLOv8's dataset. Initially, we prioritize \n",
    "# handling bounding boxes (bbox) and defer addressing segmentation aspects until we achieve satisfactory accuracy levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0828f802-7ee8-4167-82f9-eafdb1d760a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to have images folder with all the images and cocojson folder with all the labels to run codes below.\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Your directories\n",
    "coco_dir = './cocojson'  # Directory containing COCO JSON files\n",
    "labels_dir = './labels'  # Final directory to save the YOLO format files\n",
    "\n",
    "# These are index mapping we have to do.\n",
    "# YOLOv8 needs your name starting from 0 incrementing by 1.\n",
    "# Spare-it has id values not in this format, so we have mapped them in this way.\n",
    "id_to_index = {1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8, 11: 9, \n",
    "               14: 10, 15: 11, 16: 12, 17: 13, 18: 14, 19: 15, 115: 16, 114: 17, \n",
    "               116: 18, 117: 19, 122: 20, 123: 21, 124: 22, 127: 23, 20: 24, 21: 25, \n",
    "               22: 26, 23: 27, 24: 28, 25: 29, 26: 30, 27: 31, 30: 32, 125: 33, 126: 34, \n",
    "               36: 35, 38: 36, 40: 37, 43: 38, 44: 39, 45: 40, 46: 41, 47: 42, 48: 43, \n",
    "               49: 44, 50: 45, 51: 46, 52: 47, 53: 48, 54: 49, 55: 50, 56: 51, 57: 52, \n",
    "               58: 53, 59: 54, 60: 55, 120: 56, 121: 57, 63: 58, 65: 59, 66: 60, 67: 61, \n",
    "               68: 62, 69: 63, 70: 64, 72: 65, 73: 66, 76: 67, 77: 68, 78: 69, 79: 70, 80: 71, \n",
    "               82: 72, 83: 73, 84: 74, 85: 75, 86: 76, 87: 77, 88: 78, 118: 79, 119: 80, 89: 81, \n",
    "               91: 82, 92: 83, 93: 84, 94: 85, 95: 86, 96: 87, 97: 88, 98: 89, 99: 90, 100: 91, \n",
    "               101: 92, 102: 93, 103: 94, 106: 95, 107: 96, 109: 97, 110: 98, 112: 99}\n",
    "\n",
    "# Function to read Spare-it's custom COCO json into standardized YOLO format.\n",
    "# I am basing this off from Ultralytics' JSON2YOLO.\n",
    "# Reason building custom one is to have the id_to_index mapping within coco_to_yolo.\n",
    "def coco_to_yolo(coco_json_path, labels_dir, id_to_index):\n",
    "    with open(coco_json_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # We will need image_width, image_height, and overall annotation here\n",
    "    for image in data['images']:\n",
    "        image_width, image_height = image['width'], image['height']\n",
    "        yolo_annotations = [] # our converted yolo data format\n",
    "\n",
    "        for annotation in data['annotations']:\n",
    "            category_id = id_to_index.get(annotation['category_id'], -1) # convert category_id using the id_to_index mapping\n",
    "            x_min, y_min, bbox_width, bbox_height = annotation['bbox']\n",
    "            x_center = x_min + (bbox_width / 2)\n",
    "            y_center = y_min + (bbox_height / 2)\n",
    "\n",
    "            x_center_normalized = x_center / image_width\n",
    "            y_center_normalized = y_center / image_height\n",
    "            width_normalized = bbox_width / image_width\n",
    "            height_normalized = bbox_height / image_height\n",
    "\n",
    "            yolo_format = f\"{category_id} {x_center_normalized} {y_center_normalized} {width_normalized} {height_normalized}\"\n",
    "            yolo_annotations.append(yolo_format)\n",
    "\n",
    "        base_filename = os.path.splitext(os.path.basename(coco_json_path))[0]\n",
    "        output_filename = os.path.join(labels_dir, f\"{base_filename}.txt\")\n",
    "        \n",
    "        # Write output into YOLO format\n",
    "        with open(output_filename, 'w') as f:\n",
    "            for item in yolo_annotations:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\n",
    "# Creates labels directory and iterate over all cocojson files to that folder\n",
    "def convert_directory(coco_dir, labels_dir, id_to_index):\n",
    "    if not os.path.exists(labels_dir):\n",
    "        os.makedirs(labels_dir)\n",
    "\n",
    "    for filename in os.listdir(coco_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            coco_json_path = os.path.join(coco_dir, filename)\n",
    "            coco_to_yolo(coco_json_path, labels_dir, id_to_index)\n",
    "\n",
    "\n",
    "convert_directory(coco_dir, labels_dir, id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90930125-6f69-4beb-bf73-2b491af93700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have all the data formatted to conduct training the model.\n",
    "#\n",
    "# We will need to use the dataset.yml, I have generated.\n",
    "# Looks through the YOLO format id to get the label name and figure out where the train and val images are at.\n",
    "# We will need to create a main folder called datasets. Inside this there will be train and val folders. Inside each\n",
    "# of these three folder, we will have images and labels folder. By doing this you will be able to customize YOLOv8 model with own dataset.\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Generate YOLO custom dataset format\n",
    "subfolders = ['train', 'val']\n",
    "for subfolder in subfolders:\n",
    "    os.makedirs(os.path.join('./datasets', subfolder, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join('./datasets', subfolder, 'labels'), exist_ok=True)\n",
    "\n",
    "# Base dataset to create these splits\n",
    "labels_path = './labels'\n",
    "images_path = './images'\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.gif']\n",
    "\n",
    "label_files = [file for file in os.listdir(labels_path) if file.endswith('.txt')]\n",
    "random.shuffle(label_files)  # Randomize the list\n",
    "\n",
    "# Calculate split sizes\n",
    "# Change the percentange for your need\n",
    "num_total = len(label_files)\n",
    "num_train = int(num_total * 0.85)\n",
    "num_val = num_total - num_train\n",
    "\n",
    "# Split the files\n",
    "train_files = label_files[:num_train]\n",
    "val_files = label_files[num_train:]\n",
    "\n",
    "def copy_files(files, source_path_images, source_path_labels, target_path_images, target_path_labels):\n",
    "    for file in files:\n",
    "        base_filename = os.path.splitext(file)[0]\n",
    "        # Attempt to find and copy the first matching image file with any of the specified extensions\n",
    "        copied = False\n",
    "        for ext in image_extensions:\n",
    "            image_file = base_filename + ext\n",
    "            if os.path.exists(os.path.join(source_path_images, image_file)):\n",
    "                shutil.copy(os.path.join(source_path_images, image_file),\n",
    "                            os.path.join(target_path_images, image_file))\n",
    "                copied = True\n",
    "                break  # stops after first match\n",
    "        if not copied:\n",
    "            print(f\"No matching image found for {file}\")\n",
    "        else:\n",
    "            shutil.copy(os.path.join(source_path_labels, file), os.path.join(target_path_labels, file)) # Only add labels file if image exist.\n",
    "            \n",
    "# Copy files to respective directories\n",
    "copy_files(train_files, images_path, labels_path, os.path.join('./datasets', 'train', 'images'), os.path.join('./datasets', 'train', 'labels'))\n",
    "copy_files(val_files, images_path, labels_path, os.path.join('./datasets', 'val', 'images'), os.path.join('./datasets', 'val', 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff1047d-9489-419c-af64-bd34c7d1eb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script cpuinfo is installed in '/usr4/ugrad/jasonoh/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts ultralytics and yolo are installed in '/usr4/ugrad/jasonoh/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Now you have to train using the Ultralytics\n",
    "!pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dca81275-80cd-4753-baff-742329ffcfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.37 🚀 Python-3.11.6 torch-2.1.2 CUDA:0 (Tesla V100S-PCIE-32GB, 32501MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=dataset.yaml, epochs=100, time=None, patience=9, batch=25, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train72232, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train72232\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1086604  ultralytics.nn.modules.head.Detect           [100, [64, 128, 256]]         \n",
      "YOLOv8n summary: 225 layers, 3346140 parameters, 3346124 gradients, 9.7 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train72232', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed ❌. Anomalies were detected with AMP on your system that may lead to NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /projectnb/spareit/jasonoh/datasets/train/labels.cache... 1720 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1720/1720 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /projectnb/spareit/jasonoh/datasets/val/labels.cache... 304 images, 0 backgrounds, 0 corrupt: 100%|██████████| 304/304 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train72232/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=9.6e-05, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005859375000000001), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train72232\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      6.73G     0.9621      1.428      1.083        181        640: 100%|██████████| 69/69 [00:11<00:00,  5.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277       0.44      0.176      0.162      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      6.75G     0.9228      1.362      1.057        160        640: 100%|██████████| 69/69 [00:11<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.452      0.176      0.165      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      6.89G     0.9108      1.336      1.044        159        640: 100%|██████████| 69/69 [00:11<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.408      0.177      0.151     0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      6.74G     0.9241      1.355      1.055        151        640: 100%|██████████| 69/69 [00:11<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277       0.46      0.168      0.172      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      6.72G     0.9345       1.36      1.058        148        640: 100%|██████████| 69/69 [00:11<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.347      0.185      0.153     0.0975\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      6.74G     0.9231      1.345      1.052        158        640: 100%|██████████| 69/69 [00:11<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.453       0.16      0.164      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      6.87G     0.9242      1.328       1.05        157        640: 100%|██████████| 69/69 [00:11<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.527       0.16      0.168      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      6.83G     0.9348      1.325      1.052        177        640: 100%|██████████| 69/69 [00:11<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.467      0.157      0.163      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      6.87G     0.9177      1.318      1.052        119        640: 100%|██████████| 69/69 [00:11<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.518      0.158      0.171       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      6.82G     0.9133      1.299      1.051        182        640: 100%|██████████| 69/69 [00:11<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.377      0.173       0.15     0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      6.83G     0.9161      1.289      1.048        165        640: 100%|██████████| 69/69 [00:11<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.407      0.181      0.155     0.0993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      6.82G     0.8999      1.272      1.045        145        640: 100%|██████████| 69/69 [00:11<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.488      0.158      0.162      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      6.88G     0.9095      1.283      1.048        132        640: 100%|██████████| 69/69 [00:12<00:00,  5.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.424      0.177      0.151     0.0981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      6.87G     0.9333      1.326      1.059        139        640: 100%|██████████| 69/69 [00:11<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.345      0.203      0.161      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100       6.7G     0.9353      1.321      1.056        148        640: 100%|██████████| 69/69 [00:11<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.312      0.201      0.175      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      6.72G     0.9319       1.29      1.055        144        640: 100%|██████████| 69/69 [00:11<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.402        0.2      0.174      0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      6.91G     0.9279        1.3      1.051        146        640: 100%|██████████| 69/69 [00:11<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.363      0.195      0.166      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      6.82G     0.9521      1.314      1.063        143        640: 100%|██████████| 69/69 [00:11<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.428       0.18      0.163      0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      6.72G      0.983      1.384      1.082        134        640: 100%|██████████| 69/69 [00:11<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.377      0.189      0.166      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      6.91G      0.979      1.379      1.078        165        640: 100%|██████████| 69/69 [00:11<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.341       0.18      0.154     0.0994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      6.75G     0.9671      1.371      1.077        174        640: 100%|██████████| 69/69 [00:11<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.477      0.156      0.163      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      6.83G     0.9696      1.357      1.075        156        640: 100%|██████████| 69/69 [00:11<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.437      0.177      0.142     0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      6.82G     0.9688      1.347      1.077        141        640: 100%|██████████| 69/69 [00:11<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.439      0.162      0.158      0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      6.72G     0.9711      1.343      1.077        144        640: 100%|██████████| 69/69 [00:11<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.384      0.184      0.176      0.116\n",
      "Stopping training early as no improvement observed in last 9 epochs. Best results observed at epoch 15, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=9) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "24 epochs completed in 0.091 hours.\n",
      "Optimizer stripped from runs/detect/train72232/weights/last.pt, 6.9MB\n",
      "Optimizer stripped from runs/detect/train72232/weights/best.pt, 6.9MB\n",
      "\n",
      "Validating runs/detect/train72232/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.37 🚀 Python-3.11.6 torch-2.1.2 CUDA:0 (Tesla V100S-PCIE-32GB, 32501MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3340724 parameters, 0 gradients, 9.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        304       2277      0.313        0.2      0.174      0.118\n",
      "             Paper Cup        304         69      0.262       0.42      0.293      0.174\n",
      "Snack or Candy Bag or Wrapper        304        195       0.25      0.456      0.279      0.172\n",
      "             Wax Paper        304          3          1          0          0          0\n",
      "          Latex Gloves        304          5          0          0     0.0456     0.0358\n",
      "  Juice or Other Pouch        304          2          1          0      0.497      0.248\n",
      "Facemask and Other PPE        304          1          1          0     0.0995     0.0697\n",
      "   Shelf Stable Carton        304          3          0          0          0          0\n",
      "        Soiled Plastic        304         38      0.128      0.237      0.113     0.0826\n",
      "              Ceramics        304          1          0          0          0          0\n",
      "        Unclassifiable        304         49      0.235      0.102     0.0952      0.041\n",
      "            Filled Bag        304         34     0.0954      0.147     0.0621      0.041\n",
      "            Coffee Pod        304          2          0          0      0.125     0.0872\n",
      "           Other Trash        304          1      0.132          1      0.995      0.597\n",
      "Flexible container lid / seal        304         18          0          0     0.0129    0.00473\n",
      "Compostable Fiber Ware        304         52       0.34      0.596      0.438      0.339\n",
      "   Compostable Cutlery        304         14     0.0669     0.0714     0.0771     0.0431\n",
      "Compostable Plastic Cups        304          1          0          0          0          0\n",
      "Compostable Paper Cups        304          4      0.319        0.5       0.37      0.283\n",
      "Paper Towel/Napkins/Tissue        304        429      0.411       0.58      0.475      0.258\n",
      "Wooden Coffee Stirrer or Chopstick        304         30      0.233        0.1      0.132     0.0639\n",
      "  Soiled Cardboard Box        304          3          1          0       0.35      0.316\n",
      "Compostable Plastic Lid        304          9      0.299      0.444      0.419      0.331\n",
      "     Food Soiled Paper        304         41      0.173      0.193     0.0877     0.0556\n",
      "Sandwich paper wrapper        304         70      0.381      0.386      0.406      0.282\n",
      "    Fruits And Veggies        304         59      0.312      0.373      0.328      0.223\n",
      "Other Food or Mixed Food        304         30      0.213      0.267      0.189       0.13\n",
      "                Breads        304          4          0          0          0          0\n",
      "                Grains        304          1          0          0     0.0765     0.0383\n",
      "              Tea Bags        304          2          1          0    0.00664    0.00133\n",
      "        Coffee Grounds        304          3      0.447      0.667      0.557       0.29\n",
      "             Egg Shell        304          4          0          0          0          0\n",
      "         Glass Bottles        304          2      0.341        0.5      0.497      0.497\n",
      "             Metal Can        304         57      0.312      0.474       0.39      0.302\n",
      "         Aluminum Foil        304          4      0.173       0.25      0.107     0.0705\n",
      "Aluminum Catering Tray        304          1          1          0      0.142      0.128\n",
      "     Other Clean Metal        304          1          1          0          0          0\n",
      "Metallic Bottle Cap or Lid        304          6          0          0     0.0157     0.0062\n",
      "               Liquids        304          2          1          0          0          0\n",
      "Leaves, Flowers, Grass Clippings        304         22          0          0     0.0133    0.00727\n",
      "          Office Paper        304        102      0.264      0.158      0.145     0.0868\n",
      "       Clean Cardboard        304         42      0.142      0.286      0.123        0.1\n",
      "Refrigerated Beverage Carton        304          1          1          0          0          0\n",
      "   Magazines Newspaper        304         12      0.229     0.0763     0.0398     0.0317\n",
      "Receipts and Thermal Paper        304         18     0.0682      0.111     0.0783     0.0654\n",
      "       Empty Paper Bag        304        106      0.217      0.585      0.273      0.187\n",
      "Cardboard Coffee Cup Sleeve        304         20      0.184        0.5      0.346      0.203\n",
      "     Clean Paper Plate        304         17      0.215      0.471      0.337      0.287\n",
      "     Colored Memo Note        304          1          0          0    0.00526    0.00369\n",
      "            Paper Roll        304          1          1          0     0.0829      0.058\n",
      "        Wrapping Paper        304          3          0          0          0          0\n",
      "     Other Clean Paper        304        188      0.164      0.223      0.104     0.0548\n",
      "  Plastic Drink Bottle        304         64      0.275      0.578      0.389      0.214\n",
      "Plastic Milk Jug or Personal Care Bottle        304          4          0          0      0.103     0.0938\n",
      "     Empty Plastic Bag        304         41      0.205      0.268      0.156     0.0714\n",
      "Yogurt Tub or Container        304         15      0.064     0.0667     0.0343     0.0237\n",
      "Expanded Polystyrene (styrofoam)        304          5          0          0    0.00509    0.00458\n",
      "Other Clean Plastics (rigid)        304         23     0.0299     0.0435    0.00737    0.00361\n",
      "                Straws        304         80      0.413       0.45      0.366      0.227\n",
      "       Plastic Cutlery        304         20          0          0     0.0117    0.00735\n",
      "Plastic Lid except black        304         94      0.189      0.394      0.186      0.124\n",
      "     Clear Plastic Cup        304        102      0.323       0.49      0.378      0.227\n",
      "         Black Plastic        304         33      0.189      0.455      0.282      0.221\n",
      "          Plastic Wrap        304         11     0.0338     0.0909     0.0219     0.0154\n",
      "           Bubble Wrap        304          1          1          0      0.142      0.128\n",
      "  Textiles and Clothes        304          1          1          0          0          0\n",
      "Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train72232\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://docs.ultralytics.com/modes/train/\n",
    "from ultralytics import YOLO\n",
    "# model = YOLO('yolov8n.yaml')\n",
    "# model = YOLO('yolov8n.pt')\n",
    "# model = YOLO('yolov8n.yaml').load('yolov8n.pt') # build from YAML and transfer weights\n",
    "results = model.train(\n",
    "    data='dataset.yaml', # custom dataset\n",
    "    epochs=100, # default 100 ~ higher epoch was worse went to like 38\n",
    "    imgsz=640, # default 640 ~ imgsz didn't change the end result\n",
    "    batch=25, # default 16,~8 was bad\n",
    "    patience=9, # default 100\n",
    "    dropout=0.0, # default 0.0 ~ anything on above 0.1 was bad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c7192a8-3e4c-4fa4-ba54-adf2d92ef008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /projectnb/spareit/jasonoh/images/Compost_000eeeeb-0444-4f74-91e3-d6329c6e9c85_ec3a2daf-29b4-4804-9216-e6a71b07a335_35addbdb-52aa-42ac-a9c7-26ed974484f7.jpeg: 1280x960 2 Snack or Candy Bag or Wrappers, 2 Compostable Fiber Wares, 6.8ms\n",
      "Speed: 8.2ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 1280, 960)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"./images/Compost_000eeeeb-0444-4f74-91e3-d6329c6e9c85_ec3a2daf-29b4-4804-9216-e6a71b07a335_35addbdb-52aa-42ac-a9c7-26ed974484f7.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430e019-e912-41fc-8efb-e1c6f9d8873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to ONNX format\n",
    "success = model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b902a",
   "metadata": {},
   "source": [
    "## Over Sampling methods with new data sets included"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
