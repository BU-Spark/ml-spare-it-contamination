{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, test, and unmatched \n",
    "\n",
    "# Define the directory paths\n",
    "dataset_path = 'dataset'\n",
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "unmatched_path = 'unmatched'\n",
    "\n",
    "# Create the test, train, and unmatched directories\n",
    "for path in [train_path, test_path, unmatched_path]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Collect all images and annotations filenames\n",
    "images = [f for f in os.listdir(dataset_path) if f.endswith('.jpeg')]\n",
    "annotations = [f for f in os.listdir(dataset_path) if f.endswith('.json')]\n",
    "\n",
    "# init list for matched images and their corresponding annotation and unmatched images\n",
    "# I am assuming that all annotations have a corresponding image but not all images have a corresponding annotation\n",
    "# Also assuming that the match is basically the same file name but differnet file extension\n",
    "matched = []\n",
    "unmatched = []\n",
    "\n",
    "# match annotation with image\n",
    "for image in images:\n",
    "    base_file_name = image.rsplit('.', 1)[0]\n",
    "    annotation = base_file_name + '.json'\n",
    "    if annotation in annotations:\n",
    "        matched.append((image, annotation))\n",
    "    else:\n",
    "        unmatched.append(image)\n",
    "\n",
    "# 80:20 Train/Test Split \n",
    "# Random State 42\n",
    "train_pairs, test_pairs = train_test_split(matched, test_size=0.2, random_state=42)\n",
    "\n",
    "# Helper func to move files\n",
    "def move_files(file_pairs, destination):\n",
    "    for img_file, annotation in file_pairs:\n",
    "        shutil.move(os.path.join(dataset_path, img_file), os.path.join(destination, img_file))\n",
    "        shutil.move(os.path.join(dataset_path, annotation), os.path.join(destination, annotation))\n",
    "\n",
    "# Call helper func to move the files\n",
    "move_files(train_pairs, train_path)\n",
    "move_files(test_pairs, test_path)\n",
    "\n",
    "# Move unmatched images to a seperate directory\n",
    "# Can we use these images for training still or do we need to create annotations for them?\n",
    "for img_file in unmatched:\n",
    "    shutil.move(os.path.join(dataset_path, img_file), os.path.join(unmatched_path, img_file))\n",
    "\n",
    "print(f'Training Files: {len(train_pairs) * 2}')\n",
    "print(f'Testing Files: {len(test_pairs) * 2}')\n",
    "print(f'Unmatched Images: {len(unmatched)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After splitting the images and annotation randomly check if an image in the test and train has a corresponding json file\n",
    "# Check that there are no json files in the unmatched Directory\n",
    "\n",
    "def check_matching_files(directory):\n",
    "    # List all files \n",
    "    files = os.listdir(directory)\n",
    "    # Separate images and annotations\n",
    "    json_files = [f for f in files if f.endswith('.json')]\n",
    "    jpeg_files = [f for f in files if f.endswith('.jpeg')]\n",
    "    \n",
    "    # Check directory not empty\n",
    "    if not json_files or not jpeg_files:\n",
    "        return \"Empty\"\n",
    "    \n",
    "    # Randomly choose a file type \n",
    "    chosen_file_type = random.choice(['json', 'jpeg'])\n",
    "    if chosen_file_type == 'json':\n",
    "        chosen_file = random.choice(json_files)\n",
    "        corresponding_file = chosen_file.replace('.json', '.jpeg')\n",
    "    else:\n",
    "        chosen_file = random.choice(jpeg_files)\n",
    "        corresponding_file = chosen_file.replace('.jpeg', '.json')\n",
    "    \n",
    "    # Check if the corresponding file exists\n",
    "    if corresponding_file in (json_files if chosen_file_type == 'jpeg' else jpeg_files):\n",
    "        return \"Success\"\n",
    "    else:\n",
    "        return f\"Big problem!!!! {chosen_file}\"\n",
    "\n",
    "def check_unmatched_directory(directory):\n",
    "    # List all files \n",
    "    files = os.listdir(directory)\n",
    "    # Check for json files\n",
    "    json_files = [f for f in files if f.endswith('.json')]\n",
    "    \n",
    "    if json_files:\n",
    "        return f\"There are json files: {', '.join(json_files)}\"\n",
    "    else:\n",
    "        return \"Success\"\n",
    "\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "unmatched_dir = 'unmatched'\n",
    "\n",
    "# Run N times\n",
    "N = 10\n",
    "for i in range(N):\n",
    "    train_check = check_matching_files(train_dir)\n",
    "    test_check = check_matching_files(test_dir)\n",
    "    unmatched_check = check_unmatched_directory(unmatched_dir)\n",
    "\n",
    "    print(\"Train Check:\", train_check)\n",
    "    print(\"Test Check:\", test_check)\n",
    "    print(\"Unmatched Check:\", unmatched_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the names from the spareit labelling csv\n",
    "def extract_names(file_path):\n",
    "    names = []\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            if row:  \n",
    "                names.append(row[0]) \n",
    "    return names\n",
    "\n",
    "file_path = 'Spare-It Labelling Reference for 3d Party.csv'\n",
    "names = extract_names(file_path)\n",
    "\n",
    "# print(names)\n",
    "# len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split json and jpeg \n",
    "def organize_dataset(base_dir):\n",
    "    for dataset_type in ['train', 'test']:\n",
    "        dataset_path = os.path.join(base_dir, dataset_type)\n",
    "        \n",
    "        images_dir = os.path.join(dataset_path, 'images')\n",
    "        labels_dir = os.path.join(dataset_path, 'labels')\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        os.makedirs(labels_dir, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(dataset_path):\n",
    "            if filename.endswith('.jpeg'):\n",
    "                shutil.move(os.path.join(dataset_path, filename), images_dir)\n",
    "            elif filename.endswith('.json'):\n",
    "                shutil.move(os.path.join(dataset_path, filename), labels_dir)\n",
    "\n",
    "base_dir = ''  \n",
    "organize_dataset(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON to YOLO format (txt)\n",
    "def extract_categories(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    categories = data['categories']\n",
    "    print(categories)\n",
    "    return [{\"id\": cat[\"id\"], \"name\": cat[\"name\"]} for cat in categories]\n",
    "\n",
    "def convert_json_to_yolo(json_file, output_dir, categories):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    category_id_to_index = {category[\"id\"]: index for index, category in enumerate(categories)}\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_filename = os.path.splitext(os.path.basename(json_file))[0]\n",
    "    txt_filename = base_filename + '.txt'\n",
    "    txt_path = os.path.join(output_dir, txt_filename)\n",
    "\n",
    "    with open(txt_path, 'w') as f:\n",
    "        for ann in data['annotations']:\n",
    "            if ann['category_id'] not in category_id_to_index:\n",
    "                print(f\"Unknown category_id {ann['category_id']} in {json_file}\")\n",
    "                continue\n",
    "            category_index = category_id_to_index[ann['category_id']]\n",
    "            bbox = ann['bbox']\n",
    "            x_center = (bbox[0] + bbox[2] / 2) / data['images'][0]['width']\n",
    "            y_center = (bbox[1] + bbox[3] / 2) / data['images'][0]['height']\n",
    "            width = bbox[2] / data['images'][0]['width']\n",
    "            height = bbox[3] / data['images'][0]['height']\n",
    "            line = f\"{category_index} {x_center} {y_center} {width} {height}\"\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "def process_all_json_files(directory, output_dir):\n",
    "    first_json_file = next((f for f in os.listdir(directory) if f.endswith('.json')), None)\n",
    "    if first_json_file is None:\n",
    "        print(\"No JSON files found in the directory.\")\n",
    "        return\n",
    "    categories = extract_categories(os.path.join(directory, first_json_file))\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            json_file = os.path.join(directory, filename)\n",
    "            convert_json_to_yolo(json_file, output_dir, categories)\n",
    "\n",
    "annotations_dir = 'train/annotations' \n",
    "output_dir = 'train/labels'\n",
    "process_all_json_files(annotations_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dir = 'test/annotations' \n",
    "output_dir = 'test/labels'\n",
    "process_all_json_files(annotations_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the category names for the data.yaml folder\n",
    "def extract_categories(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    categories = data['categories']\n",
    "    print([cat[\"name\"] for cat in categories])\n",
    "\n",
    "directory='train/annotations'\n",
    "first_json_file = next((f for f in os.listdir(directory) if f.endswith('.json')), None)\n",
    "extract_categories(os.path.join(directory, first_json_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
